{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Making Predictions\n",
    "\n",
    "1. Save the trained model to `.pkl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization completed and saved.\n",
      "Accuracy: 0.8975\n",
      "\n",
      "Classification Report Logistic Regression with OneVsRest and SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.88      0.93      0.90       106\n",
      "       entertainment       0.86      0.82      0.84       130\n",
      "             fashion       0.88      0.90      0.89       135\n",
      "                food       0.89      0.88      0.89       120\n",
      "              gaming       0.98      1.00      0.99       124\n",
      "health and lifestyle       0.77      0.67      0.72       118\n",
      "    mom and children       0.97      0.98      0.97       121\n",
      "              sports       0.99      0.99      0.99       101\n",
      "                tech       0.88      0.93      0.90       124\n",
      "              travel       0.88      0.88      0.88       121\n",
      "\n",
      "            accuracy                           0.90      1200\n",
      "           macro avg       0.90      0.90      0.90      1200\n",
      "        weighted avg       0.90      0.90      0.90      1200\n",
      "\n",
      "Model saved to logistic_regression_model.pkl\n",
      "TF-IDF vectorizer saved to tfidf_vectorizer.pkl\n",
      "Model and vectorizer loaded successfully.\n",
      "Predicted Categories for New Data: ['health and lifestyle' 'food']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# ====================\n",
    "# Step 1: Load and Preprocess Data\n",
    "# ====================\n",
    "# Load the JSON dataset\n",
    "file_path = '../merged_profiles.json'  # Replace with your actual file path\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert JSON data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure the 'text' column is selected for TF-IDF vectorization\n",
    "texts = df['text']\n",
    "categories = df['category']  # Target variable\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Add the category column to the TF-IDF DataFrame\n",
    "tfidf_df['category'] = categories\n",
    "\n",
    "# Save the TF-IDF DataFrame for future reference\n",
    "tfidf_vectorized_file = 'tfidf_vectorized.csv'\n",
    "tfidf_df.to_csv(tfidf_vectorized_file, index=False)\n",
    "print(\"TF-IDF vectorization completed and saved.\")\n",
    "\n",
    "# ====================\n",
    "# Step 2: Train the Model\n",
    "# ====================\n",
    "# Separate features and target\n",
    "X = tfidf_df.drop('category', axis=1)\n",
    "y = tfidf_df['category']\n",
    "\n",
    "# Set the threshold for underrepresented categories\n",
    "threshold = 600\n",
    "\n",
    "# Identify categories with less than threshold samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Define the best hyperparameters directly\n",
    "best_params = {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
    "base_lr = LogisticRegression(random_state=42, max_iter=1000, **best_params)\n",
    "best_lr = OneVsRestClassifier(base_lr)\n",
    "\n",
    "# Train the model\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Logistic Regression with OneVsRest and SMOTE:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and TF-IDF vectorizer\n",
    "model_filename = 'logistic_regression_model.pkl'\n",
    "vectorizer_filename = 'tfidf_vectorizer.pkl'\n",
    "joblib.dump(best_lr, model_filename)\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "print(f\"TF-IDF vectorizer saved to {vectorizer_filename}\")\n",
    "\n",
    "# ====================\n",
    "# Step 3: Load and Predict on New Data\n",
    "# ====================\n",
    "# Load the saved model and vectorizer\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_vectorizer = joblib.load(vectorizer_filename)\n",
    "print(\"Model and vectorizer loaded successfully.\")\n",
    "\n",
    "# Example: Predict categories for new accounts\n",
    "new_texts = [\"This is an example bio or caption.\", \"Another profile description here.\"]  # Replace with actual text\n",
    "new_data_matrix = loaded_vectorizer.transform(new_texts)\n",
    "new_data_predictions = loaded_model.predict(new_data_matrix)\n",
    "\n",
    "# Output predictions\n",
    "print(\"Predicted Categories for New Data:\", new_data_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using data from a `.dat` file, selectively taken from `processed_files.json`.\n",
    "3. Save the result to `filtered_profiles.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered profiles saved to filtered_profiles.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ====================\n",
    "# Load Processed Profiles\n",
    "# ====================\n",
    "processed_profiles_file = '../processed_profiles.json'  # Update with your file path\n",
    "with open(processed_profiles_file, 'r', encoding='utf-8') as file:\n",
    "    processed_profiles = json.load(file)\n",
    "\n",
    "# ====================\n",
    "# Load Usernames from .dat File\n",
    "# ====================\n",
    "usernames_file = 'test-classification-round3.dat'  # Update with your file path\n",
    "\n",
    "# Read usernames from the .dat file\n",
    "with open(usernames_file, 'r', encoding='utf-8') as file:\n",
    "    usernames = set(line.strip() for line in file)  # Assuming one username per line\n",
    "\n",
    "# ====================\n",
    "# Filter Profiles by Usernames\n",
    "# ====================\n",
    "filtered_profiles = [\n",
    "    profile for profile in processed_profiles if profile[\"username\"] in usernames\n",
    "]\n",
    "\n",
    "# ====================\n",
    "# Save Filtered Profiles\n",
    "# ====================\n",
    "filtered_profiles_file = 'filtered_profiles.json'\n",
    "with open(filtered_profiles_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filtered_profiles, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Filtered profiles saved to {filtered_profiles_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Processing the `text` field from the data for prediction.\n",
    "5. Saving predictions to `prediction-classification-round*.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction-classification-round3.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "\n",
    "# ====================\n",
    "# Load Filtered Profiles\n",
    "# ====================\n",
    "filtered_profiles_file = 'filtered_profiles.json'  # Update if necessary\n",
    "with open(filtered_profiles_file, 'r', encoding='utf-8') as file:\n",
    "    filtered_profiles = json.load(file)\n",
    "\n",
    "# ====================\n",
    "# Load the Saved Model and TF-IDF Vectorizer\n",
    "# ====================\n",
    "model_file = 'logistic_regression_model.pkl'  # Update if necessary\n",
    "vectorizer_file = 'tfidf_vectorizer.pkl'  # Update if necessary\n",
    "loaded_model = joblib.load(model_file)\n",
    "loaded_vectorizer = joblib.load(vectorizer_file)\n",
    "\n",
    "# ====================\n",
    "# Prepare the Text Data for Prediction\n",
    "# ====================\n",
    "# Extract usernames and texts\n",
    "usernames = [profile['username'] for profile in filtered_profiles]\n",
    "texts = [profile['text'] for profile in filtered_profiles]\n",
    "\n",
    "# Transform the texts using the loaded vectorizer\n",
    "text_vectors = loaded_vectorizer.transform(texts)\n",
    "\n",
    "# Predict labels using the loaded model\n",
    "predicted_labels = loaded_model.predict(text_vectors)\n",
    "\n",
    "# ====================\n",
    "# Create the Output JSON Object\n",
    "# ====================\n",
    "# Map usernames to predicted labels\n",
    "output = {usernames[i]: predicted_labels[i] for i in range(len(usernames))}\n",
    "\n",
    "# Save the output to a JSON file\n",
    "output_file = 'prediction-classification-round3.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(output, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
