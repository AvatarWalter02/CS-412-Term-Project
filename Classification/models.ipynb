{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training and Selection\n",
    "\n",
    "This section covers:\n",
    "1. Processing text data using TF-IDF vectorization (output saved for reuse as `tfidf_vectorized.csv`).\n",
    "2. Using SMOTE to balance training data for underrepresented categories.\n",
    "3. Training and evaluating various classification models:\n",
    "   - Random Forest\n",
    "   - Support Vector Machine (SVM)\n",
    "   - k-Nearest Neighbors (k-NN)\n",
    "   - Naive Bayes\n",
    "   - Logistic Regression\n",
    "   - Logistic Regression with One-vs-Rest (OvR) strategy.\n",
    "   - Decision Tree\n",
    "4. Hyperparameter tuning with GridSearch to optimize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 TF-IDF Vectorization\n",
    "\n",
    "The text data is processed using TF-IDF vectorizer, and the output is saved to `tfidf_vectorized.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          username                                               text  \\\n",
      "0    taskirancemal  cemal taşkıran kaş ah merve çocuk bak ol kork ...   \n",
      "1    tam_kararinda  kaan yâr milliyet pazar kalori ala fayda deney...   \n",
      "2         spart4nn  cemil ceylân küçük ev kamp doğa mutfak reklam ...   \n",
      "3  sosyalyiyiciler  keşif keşif çakal menemen ekstra dahil sınır ç...   \n",
      "4  sonaydizdarahad  sonay dizdar dağhan eyvallah şanlıurfa ener ar...   \n",
      "\n",
      "           category  \n",
      "0  mom and children  \n",
      "1              food  \n",
      "2              food  \n",
      "3              food  \n",
      "4  mom and children  \n",
      "TF-IDF vectorization completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the JSON dataset\n",
    "file_path = 'merged_profiles.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the 'text' column is selected for TF-IDF vectorization\n",
    "texts = df['text']\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    # norm='l2',\n",
    "    # ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Add the category column for reference\n",
    "tfidf_df['category'] = df['category']\n",
    "\n",
    "# Save the TF-IDF DataFrame or inspect it\n",
    "tfidf_df.to_csv('tfidf_vectorized.csv', index=False)\n",
    "print(\"TF-IDF vectorization completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.697560975609756\n",
      "\n",
      "Classification Report Random Forest with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.67      0.15      0.24        41\n",
      "       entertainment       0.51      0.45      0.47        74\n",
      "             fashion       0.68      0.73      0.70        66\n",
      "                food       0.78      0.90      0.84        99\n",
      "              gaming       1.00      1.00      1.00        36\n",
      "health and lifestyle       0.54      0.74      0.63       103\n",
      "    mom and children       0.96      0.64      0.77        39\n",
      "              sports       0.96      0.75      0.84        36\n",
      "                tech       0.72      0.81      0.76        77\n",
      "              travel       0.68      0.61      0.64        44\n",
      "\n",
      "            accuracy                           0.70       615\n",
      "           macro avg       0.75      0.68      0.69       615\n",
      "        weighted avg       0.71      0.70      0.69       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': None,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 10,\n",
    "    'n_estimators': 200\n",
    "}\n",
    "best_rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Random Forest with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6943089430894309\n",
      "\n",
      "Classification Report SVM with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.43      0.24      0.31        41\n",
      "       entertainment       0.50      0.50      0.50        74\n",
      "             fashion       0.63      0.62      0.63        66\n",
      "                food       0.82      0.84      0.83        99\n",
      "              gaming       1.00      1.00      1.00        36\n",
      "health and lifestyle       0.61      0.70      0.65       103\n",
      "    mom and children       0.91      0.82      0.86        39\n",
      "              sports       0.96      0.72      0.83        36\n",
      "                tech       0.71      0.75      0.73        77\n",
      "              travel       0.60      0.73      0.66        44\n",
      "\n",
      "            accuracy                           0.69       615\n",
      "           macro avg       0.72      0.69      0.70       615\n",
      "        weighted avg       0.70      0.69      0.69       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'degree': [2, 3, 4],  # Only relevant for 'poly' kernel\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "# svm = SVC(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_svm = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "\n",
    "best_svm = SVC(random_state=42, **best_params)\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report SVM with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6894308943089431\n",
      "\n",
      "Classification Report Naive Bayes with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.67      0.20      0.30        41\n",
      "       entertainment       0.50      0.41      0.45        74\n",
      "             fashion       0.72      0.67      0.69        66\n",
      "                food       0.87      0.83      0.85        99\n",
      "              gaming       1.00      1.00      1.00        36\n",
      "health and lifestyle       0.55      0.76      0.63       103\n",
      "    mom and children       0.86      0.64      0.74        39\n",
      "              sports       0.86      0.67      0.75        36\n",
      "                tech       0.70      0.83      0.76        77\n",
      "              travel       0.55      0.75      0.63        44\n",
      "\n",
      "            accuracy                           0.69       615\n",
      "           macro avg       0.73      0.67      0.68       615\n",
      "        weighted avg       0.70      0.69      0.68       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'alpha': [0.1, 0.5, 1.0],  # Smoothing parameter\n",
    "# }\n",
    "# nb = MultinomialNB()\n",
    "# grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_nb = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'alpha': 0.1}  # Default smoothing parameter\n",
    "best_nb = MultinomialNB(**best_params)\n",
    "best_nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Naive Bayes with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4991869918699187\n",
      "\n",
      "Classification Report Decision Tree with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.17      0.20      0.18        41\n",
      "       entertainment       0.30      0.32      0.31        74\n",
      "             fashion       0.48      0.50      0.49        66\n",
      "                food       0.67      0.65      0.66        99\n",
      "              gaming       0.94      0.94      0.94        36\n",
      "health and lifestyle       0.44      0.40      0.42       103\n",
      "    mom and children       0.50      0.62      0.55        39\n",
      "              sports       0.70      0.44      0.54        36\n",
      "                tech       0.53      0.61      0.57        77\n",
      "              travel       0.46      0.36      0.41        44\n",
      "\n",
      "            accuracy                           0.50       615\n",
      "           macro avg       0.52      0.50      0.51       615\n",
      "        weighted avg       0.51      0.50      0.50       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],  # Splitting criterion\n",
    "#     'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],  # Minimum samples required to split\n",
    "#     'min_samples_leaf': [1, 2, 4],    # Minimum samples per leaf\n",
    "# }\n",
    "# dt = DecisionTreeClassifier(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_dt = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
    "best_dt = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Decision Tree with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.375609756097561\n",
      "\n",
      "Classification Report K-NN with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.55      0.15      0.23        41\n",
      "       entertainment       0.00      0.00      0.00        74\n",
      "             fashion       0.67      0.06      0.11        66\n",
      "                food       0.92      0.36      0.52        99\n",
      "              gaming       0.97      1.00      0.99        36\n",
      "health and lifestyle       0.21      0.87      0.33       103\n",
      "    mom and children       0.88      0.56      0.69        39\n",
      "              sports       0.89      0.67      0.76        36\n",
      "                tech       0.60      0.04      0.07        77\n",
      "              travel       0.34      0.23      0.27        44\n",
      "\n",
      "            accuracy                           0.38       615\n",
      "           macro avg       0.60      0.39      0.40       615\n",
      "        weighted avg       0.56      0.38      0.34       615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9],  # Number of neighbors\n",
    "#     'weights': ['uniform', 'distance'],  # Weighting strategy\n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski']  # Distance metric\n",
    "# }\n",
    "# knn = KNeighborsClassifier()\n",
    "# grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_knn = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report K-NN with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Rgression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7138211382113822\n",
      "\n",
      "Classification Report Logistic Regression with SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.41      0.27      0.32        41\n",
      "       entertainment       0.53      0.49      0.51        74\n",
      "             fashion       0.73      0.68      0.70        66\n",
      "                food       0.79      0.90      0.84        99\n",
      "              gaming       0.97      1.00      0.99        36\n",
      "health and lifestyle       0.66      0.69      0.67       103\n",
      "    mom and children       0.91      0.79      0.85        39\n",
      "              sports       0.97      0.81      0.88        36\n",
      "                tech       0.67      0.78      0.72        77\n",
      "              travel       0.66      0.70      0.68        44\n",
      "\n",
      "            accuracy                           0.71       615\n",
      "           macro avg       0.73      0.71      0.72       615\n",
      "        weighted avg       0.71      0.71      0.71       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# Identify categories with less than 200 samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],         # Regularization strength\n",
    "#     'penalty': ['l2'],              # Regularization type\n",
    "#     'solver': ['lbfgs', 'saga'],    # Solvers for optimization\n",
    "#     'multi_class': ['ovr', 'multinomial']  # Multiclass strategy\n",
    "# }\n",
    "# lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "# grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_lr = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'C': 10, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'}\n",
    "best_lr = LogisticRegression(random_state=42, max_iter=1000, **best_params)\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Logistic Regression with SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model: Logistic Regression with OvR and SMOTE\n",
    "\n",
    "This section focuses on:\n",
    "- Training and optimizing the best-performing model: **Logistic Regression with One-vs-Rest (OvR)**.\n",
    "- Balancing the data with SMOTE using an optimized threshold of 600.\n",
    "\n",
    "The final model is in a dedicated directory, called 'model' for reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8975\n",
      "\n",
      "Classification Report Logistic Regression with OneVsRest and SMOTE:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                 art       0.88      0.93      0.90       106\n",
      "       entertainment       0.86      0.82      0.84       130\n",
      "             fashion       0.88      0.90      0.89       135\n",
      "                food       0.89      0.88      0.89       120\n",
      "              gaming       0.98      1.00      0.99       124\n",
      "health and lifestyle       0.77      0.67      0.72       118\n",
      "    mom and children       0.97      0.98      0.97       121\n",
      "              sports       0.99      0.99      0.99       101\n",
      "                tech       0.88      0.93      0.90       124\n",
      "              travel       0.88      0.88      0.88       121\n",
      "\n",
      "            accuracy                           0.90      1200\n",
      "           macro avg       0.90      0.90      0.90      1200\n",
      "        weighted avg       0.90      0.90      0.90      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the TF-IDF Vectorized Data\n",
    "file_path = 'tfidf_vectorized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('category', axis=1)\n",
    "y = df['category']\n",
    "\n",
    "threshold = 600\n",
    "\n",
    "# Identify categories with less than threhold samples\n",
    "category_counts = y.value_counts()\n",
    "categories_to_resample = category_counts[category_counts < threshold].index\n",
    "\n",
    "# Apply SMOTE only to underrepresented categories\n",
    "smote = SMOTE(sampling_strategy={category: threshold for category in categories_to_resample}, random_state=21)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=21)\n",
    "\n",
    "# Comment/uncomment the sections below based on your requirement\n",
    "\n",
    "# 1. Perform Grid Search\n",
    "# Uncomment this section to find the best parameters using Grid Search\n",
    "# param_grid = {\n",
    "#     'estimator__C': [0.1, 1, 10, 100],         # Regularization strength\n",
    "#     'estimator__penalty': ['l2'],              # Regularization type\n",
    "#     'estimator__solver': ['lbfgs', 'saga']     # Solvers for optimization\n",
    "# }\n",
    "# lr = OneVsRestClassifier(LogisticRegression(random_state=42, max_iter=1000))\n",
    "# grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# best_lr = grid_search.best_estimator_\n",
    "\n",
    "# 2. Use Predefined Best Parameters\n",
    "# Uncomment this section if you want to directly use predefined parameters\n",
    "best_params = {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
    "base_lr = LogisticRegression(random_state=21, max_iter=1000, **best_params)\n",
    "best_lr = OneVsRestClassifier(base_lr)\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report Logistic Regression with OneVsRest and SMOTE:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
